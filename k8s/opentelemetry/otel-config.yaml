receivers:
  # Push based metrics
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
  # Pull based metrics
  #prometheus:
  #  config:
  #    scrape_configs:
  #      - job_name: 'kubernetes-service-endpoints'
  #        scrape_interval: 10s
  #        scrape_timeout: 1s

  #        kubernetes_sd_configs:
  #        - role: pod

  #        # Only container ports named `metrics` will be considered valid targets.
  #        #
  #        # Setup relabel rules to give meaning to the following k8s annotations:
  #        #   prometheus/path - URL path of the metrics endpoint
  #        #
  #        # Example:
  #        #   annotations:
  #        #      prometheus/path: "/api/v0/metrics"
  #        relabel_configs:
  #        - source_labels: [__meta_kubernetes_pod_container_port_name]
  #          action: keep
  #          regex: "metrics"
  #        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_path]
  #          action: replace
  #          target_label: __metrics_path__
  #          regex: (.+)
  #        - source_labels: [__meta_kubernetes_namespace]
  #          action: replace
  #          target_label: kubernetes_namespace
  #        - source_labels: [__meta_kubernetes_pod_name]
  #          action: replace
  #          target_label: kubernetes_pod
  #        - source_labels: [__meta_kubernetes_pod_container_name]
  #          action: replace
  #          target_label: kubernetes_container

processors:
  batch:

exporters:
  # This is unused but can be easily added for debugging.
  logging:
    # can be one of detailed | normal | basic
    verbosity: detailed
    # Log all messages, do not sample
    sampling_initial: 1
    sampling_thereafter: 1
  otlp/jaeger:
    endpoint: jaeger:4317
    tls:
      insecure: true
  prometheus:
    endpoint: 0.0.0.0:9090
    # Keep stale metrics around for 1h before dropping
    # This helps as simulation metrics are stale once the simulation stops.
    metric_expiration: 1h
    resource_to_telemetry_conversion: 
      enabled: true
  parquet:
    path: /data/
  # Grafana Cloud export
  # TODO: Remove, this work however its not possible to
  # namespace the metrics from other Grafana metrics which makes
  # it hard to consume and polutes the normal metrics namespace.
  #
  # For now leaving this here as an example of how to enable,
  # but will rely on local prometheus metrics in the short term.
  #otlphttp/grafana:
  #  auth:
  #    authenticator: basicauth/grafana
  #  endpoint: https://otlp-gateway-prod-us-central-0.grafana.net/otlp

        #extensions:
        #  basicauth/grafana:
        #    client_auth:
        #      username: "#" # replace with Grafana instance id
        #      password: "password" # replace with Grafana API token (via a secret)

service:
  #extensions: [basicauth/grafana]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp/jaeger]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [parquet, prometheus]
  # Enable telemetry on the collector itself
  telemetry:
    logs:
      level: info
    metrics:
      level: detailed
      address: 0.0.0.0:8888
